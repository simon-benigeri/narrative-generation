# Experiment Results and Next Steps

## Task

## Datasets

## Models used

## Performance metrics


1. We trained on small and medium GPT-2 models. We used data from 1 genre and then from about 20 genres. We tested on hand crafted prompts and on large samples of unseen, prompts from the script lines dataset.
    - more data improved performance
    - GPT2-medium yielded better results than GPT2-small
    - testing on extracted vs hadcrafted prompts did not affect results.

2. Tradeoff between emotion & coherence. Can we propose a test for this?

3. Improve
